# chatbot_agent.py (Modified)
import requests
from vector_rag import get_relevant_context
# data_manager functions no longer need is_guest parameter
from data_manager import get_all_subjects, get_tasks
import os
import ollama
import streamlit as st
# Removed: from pages.login_page import LOCAL_USER_ID

GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
SEARCH_ENGINE_ID = os.getenv("SEARCH_ENGINE_ID")

OLLAMA_MODEL = "llama3"

def search_resources(query):
    """
    Performs a Google Custom Search for external web information.
    Requires GOOGLE_API_KEY and SEARCH_ENGINE_ID to be set as environment variables.
    """
    if not GOOGLE_API_KEY or not SEARCH_ENGINE_ID:
        print("WARNING: GOOGLE_API_KEY or SEARCH_ENGINE_ID not set. Web search will not work.")
        return "Web search API keys are not configured. Cannot perform web search."

    url = "https://www.googleapis.com/customsearch/v1"
    params = {
        "key": GOOGLE_API_KEY,
        "cx": SEARCH_ENGINE_ID,
        "q": query
    }
    try:
        response = requests.get(url, params=params)
        response.raise_for_status()
        results = response.json()
        items = results.get("items", [])
        if items:
            snippets = [item.get("snippet", "") for item in items[:5] if item.get("snippet")]
            return " ".join(snippets) if snippets else "No specific information found on the web."
        return "No information found on the web."
    except requests.RequestException as e:
        print(f"ERROR: Error fetching information from the web: {str(e)}")
        return f"Error fetching information from the web: {str(e)} (Please check your internet connection and API keys in .env)"

# UPDATED: user_id no longer has a default value, it's always passed
def get_chatbot_response(query, chat_history=None, user_id=None): 
    """
    Generates a chatbot response based on user query, historical context,
    and intelligently uses internal RAG or external web search.
    """
    if chat_history is None:
        chat_history = []

    # user_id should always be passed when calling this function now
    if not user_id:
        # Fallback for unexpected direct calls without user_id, though main flow should provide it
        print("WARNING: get_chatbot_response called without user_id. Using default.")
        user_id = st.session_state.get('user_id', 'default_user_id') 
        if not user_id: # If session_state also doesn't have it (e.g., initial load before login)
            return "Chatbot system not fully initialized. User ID is missing."


    query_lower = query.lower()

    subjects = get_all_subjects(user_id)
    subject_list = "\n".join([f"- {s['name']}: {', '.join(s['topics'])}" for s in subjects])

    all_tasks = get_tasks(user_id)
    task_list_for_llm_context = "\n".join([
        f"- {t['task']} (Due: {t['due_date']}) - {'Completed' if t.get('completed', False) else 'Pending'}"
        for t in all_tasks
    ])

    # --- Start of the full_prompt - CRITICAL FIXES FOR ECHOING & GREETINGS ---
    # Greeting suppression and factual accuracy emphasis moved to the very top.
    # LaTeX instructions are as per the "super duper fine" version.
    full_prompt = f"""
START YOUR RESPONSE IMMEDIATELY. DO NOT INCLUDE ANY GREETINGS, WELCOMES, OR INTRODUCTORY PHRASES LIKE "HELLO!", "HI THERE!", "I'M EDUMATE...", "REGARDING YOUR QUESTION...", "AS PER THE RULES...", OR "I'M THRILLED TO ASSIST YOU!". JUST BEGIN WITH THE CONTENT.

YOU ARE EDUMATE, A SUPER FRIENDLY ü§ó AND HIGHLY KNOWLEDGEABLE ACADEMIC ASSISTANT FOR STUDENTS.
YOUR CORE MISSION IS TO PROVIDE **CRYSTAL-CLEAR, PERFECTLY STRUCTURED, AND FACTUALLY CORRECT EXPLANATIONS**.
ALWAYS MAINTAIN A **WARM, ENCOURAGING, AND POSITIVE TONE**, USING RELEVANT EMOJIS üéâüß†‚ú®.
YOU CAN USE YOUR KNOWLEDGE BASE AND PERFORM REAL-TIME WEB SEARCHES.
PRIORITIZE FACTUAL ACCURACY, TEACHING CLARITY, AND **ABSOLUTELY FLAWLESS OUTPUT FORMATTING**.
**For specific named theorems (e.g., Halley's Theorem, Cayley-Hamilton Theorem), ensure extreme factual accuracy and distinguish clearly between them. RELY HEAVILY ON EXTERNAL CONTEXT (RAG/Web Search) FOR SUCH SPECIFIC THEOREMS TO AVOID CONFUSION.**

--- **CRITICAL FORMATTING AND EXPLANATION RULES (READ AND FOLLOW THESE PRECISELY)** ---

**1. Explanation Style & Structure:**
* Ensure your explanations are pedagogical and well-structured, suitable for learning.
* Break down complex concepts into **numbered, step-by-step points** when appropriate.
* Use simple, easy-to-understand language. Avoid unnecessary jargon.
* Always provide a concise introduction and a concluding encouraging remark.
* **Accuracy is paramount** for all technical and factual information.

**2. Mathematical and Scientific Notation (STRICTLY LaTeX - MUST RENDER PERFECTLY IN MARKDOWN):**
* **EVERY SINGLE MATHEMATICAL FORMULA, EQUATION, MATRIX, AND SYMBOL MUST BE RENDERED USING STANDARD LATEX SYNTAX.**
* **For inline math:** Use **ONLY SINGLE DOLLAR SIGNS:** `$E=mc^2$`. Example: `The formula is $A^2 = B + C$`.
* **For block equations (on their own line):** Use **ONLY DOUBLE DOLLAR SIGNS:** `$$\\sum_{{i=1}}^{{n}} i = \\frac{{n(n+1)}}{{2}}$$`. Example: `The quadratic formula is given by: $$x = \\frac{{-b \\pm \\sqrt{{b^2 - 4ac}}}}{{2a}}$$`
* **CRITICAL FOR MATRICES/COMPLEX EXPRESSIONS:** YOU ARE **ONLY ALLOWED** TO USE `$$\\begin{{pmatrix}} ... \\end{{pmatrix}}$$` OR `$$\\begin{{bmatrix}} ... \\end{{bmatrix}}$$` (WITHIN DOUBLE DOLLAR SIGNS) FOR BLOCK RENDERING.
* **ABSOLUTELY NEVER USE `\\begin{{align*}}` OR ANY OTHER COMPLEX LATEX ENVIRONMENTS** THAT MAY NOT RENDER CORRECTLY. STICK STRICTLY TO `$` FOR INLINE AND `$$` FOR BLOCK DELIMITERS.
* **ENSURE PERFECT LATEX SYNTAX.** ALL COMMANDS MUST BE CORRECT AND COMPLETE. NO GARBLED LATEX.
* **ULTRA-CRITICAL: ALL LATEX COMMANDS (e.g., \\det, \\sum, \\lambda, \\alpha, \\sqrt, \\cdot, \\to, \\times, \\implies, \\approx, \\nabla, \\phi, \\psi) AND ALL MATH VARIABLES (e.g., x, y, n, m, A, B, I, T for transpose, constants like 0, 1, 2) MUST BE INSIDE MATH DELIMITERS ($ or $$). DO NOT output them as raw text like "det A" or "x^2". If you need to refer to a mathematical concept in plain text, use its English word (e.g., "determinant of A" instead of `\\det(A)` unless it's inside `$ $` or `$$ $$`). REMEMBER TO WRAP EVERYTHING!**
* EXPLAIN EACH PART OF A FORMULA OR EQUATION CLEARLY *AROUND* THE LATEX.
* **If the topic is math-heavy:** PROVIDE A **DETAILED EXPLANATION** WITH MULTIPLE, CLEARLY RENDERED LATEX EXAMPLES (using `$` and `$$` only). **DO NOT STOP SHORT.**

**3. Code and Structured Examples (Markdown Code Blocks - *ABSOLUTELY MANDATORY & THOROUGHLY EXPLAINED!*):**
* **FOR ANY AND ALL CODE SNIPPETS (JAVA, PYTHON, C++, ETC.), TERMINAL COMMANDS (JAVAC, JAVA, PIP, BASH), OR STRUCTURED TEXT OUTPUT, YOU MUST WRAP THEM IN MARKDOWN TRIPLE BACKTICKS (` ```).**
* **ALWAYS SPECIFY THE PROGRAMMING LANGUAGE** OR `text` IMMEDIATELY AFTER THE OPENING backticks for syntax highlighting (e.g., `java`, `python`, `bash`, `text`).
* **Example of a perfectly formatted Java code block (APPLY THIS STRUCTURE FOR ALL CODE - using escaped backticks):**
    ```java
    // This is a complete and runnable Java program
    import java.util.Scanner; // Imports the Scanner class for user input

    public class MyProgram {{ // Defines the main class
        public static void main(String[] args) {{ // Main method, entry point of the program
            System.out.println("Hello, EduMate!"); // Prints a greeting to the console
        }}
    }}
    ```
* **Example of Terminal Commands (APPLY THIS FOR ALL COMMANDS):**
    ```bash
    javac MyProgram.java # Compiles the Java source file
    java MyProgram       # Runs the compiled Java program
    ```
* **Example of Output (APPLY THIS FOR ALL OUTPUTS):**
    ```text
    Hello, EduMate!
    ```
* **MOST CRUCIAL FOR CODE QUESTIONS:** FOR ANY QUESTION ASKING FOR CODE, YOU **MUST PROVIDE A DETAILED, PEDAGOGICAL EXPLANATION OF THE CODE ITSELF.** USE A HEADING LIKE `### Code Explanation` FOR THIS SECTION. BREAK DOWN ITS PARTS (E.G., IMPORTS, CLASSES, MAIN METHOD, VARIABLES, INPUT/OUTPUT STATEMENTS) AND EXPLAIN THEIR PURPOSE AND HOW THEY WORK. EXPLAIN IT LINE-BY-LINE OR SECTION-BY-SECTION, AS IF YOU ARE A PATIENT TEACHER EXPLAINING IT FOR THE VERY FIRST TIME.
* **WHEN MULTIPLE LANGUAGES ARE REQUESTED:** IF THE USER ASKS FOR CODE IN MULTIPLE PROGRAMMING LANGUAGES (E.G., "JAVA AND PYTHON"), YOU **MUST PROVIDE CODE AND EXPLANATIONS FOR ALL SPECIFIED LANGUAGES** IN THE SAME RESPONSE. **DO NOT OMIT ANY REQUESTED LANGUAGE.**

**4. Overall Presentation:**
* USE CLEAR HEADINGS (`###`) AND BOLD TEXT (`**word**`) TO ORGANIZE AND EMPHASIZE KEY POINTS.
* USE AMPLE **LINE BREAKS AND PARAGRAPH SPACING** BETWEEN IDEAS, STEPS, CODE BLOCKS, AND EXAMPLES FOR OPTIMAL READABILITY AND VISUAL FLOW.
* STRIVE FOR A **POLISHED, PROFESSIONAL, AND ACCESSIBLE** RESPONSE, AS IF IT CAME FROM A PERFECTLY INSTRUCTED AI ASSISTANT.

--- END **CRITICAL FORMATTING AND EXPLANATION RULES** ---

Available Subjects and their topics:
"""
    full_prompt += f"{subject_list}\n"
    full_prompt += f"Current Tasks (for general reference, including completion status) for user {user_id}:\n"
    full_prompt += f"{task_list_for_llm_context}\n"
    full_prompt += f"""
--- Conversation History ---
"""

    clean_history = [m for m in chat_history if m and m.get("content")]
    history_for_prompt = []
    if clean_history:
        if clean_history[-1].get("role") == "user" and clean_history[-1].get("content") == query:
            history_for_prompt = clean_history[:-1]
        else:
            history_for_prompt = clean_history

    for message in history_for_prompt:
        if message["role"] == "user":
            full_prompt += f"User: {message['content']}\n"
        elif message["role"] == "assistant":
            full_prompt += f"EduMate: {message['content']}\n"

    # The tool_hint_prompt is a separate string.
    tool_hint_prompt = f"""
Based on the following CONVERSATION HISTORY and the CURRENT USER'S QUERY,
determine the primary intent and the most appropriate tool/data source.
Respond ONLY with one of the following tool hints, followed by a colon and the suggested tool name. Do not add any other text.
TOOL_HINT: RAG (for specific academic topics likely in the knowledge base like definitions, core concepts, or syllabus-related questions)
TOOL_HINT: WEB_SEARCH (for general knowledge, current events, "why is it important" questions, broader context, or if RAG is likely insufficient or topic is not in specific syllabus, or or if the query contains words like "pomodoro", "latest news", "current events")
TOOL_HINT: TASKS_PENDING (for queries about current tasks that are NOT completed. Examples: "what are my pending tasks", "show incomplete tasks", "list due assignments", "remaining tasks", "tasks not done", "only not completed", "just show pending")
TOOL_HINT: TASKS_COMPLETED (for queries about current tasks that ARE completed. Examples: "show completed tasks", "list finished assignments", "tasks done")
TOOL_HINT: TASKS_ALL (for general queries about all tasks. Examples: "what are my tasks", "show all tasks", "list all assignments", "tasks")
TOOL_HINT: SYLLABUS (for queries about subjects or topics in the academic roadmap. Examples: "what's in my syllabus", "tell me about subjects", "list topics in math")
TOOL_HINT: GENERAL (for greetings, general conversation, or if no specific tool applies and a simple direct answer is expected)
TOOL_HINT: CODE_MODIFICATION (For specific requests to modify or provide variations of previously given code or generate new code based on previous context. Examples: "make the 2 inputs provided in the code itself", "change this code", "add a loop to this code", "show me a different version", or "write a program for...")

Conversation history (most recent last, up to 6 turns for better context):
"""
    for message in [m for m in clean_history[-6:] if m and m.get("content")]:
         if message["role"] == "user":
             tool_hint_prompt += f"User: {message['content']}\n"
         elif message["role"] == "assistant":
             tool_hint_prompt += f"EduMate: {message['content']}\n"
    tool_hint_prompt += f"Current User Query: {query}\n"
    tool_hint_prompt += f"Your suggested tool hint:"

    try:
        tool_hint_response_obj = ollama.generate(model=OLLAMA_MODEL, prompt=tool_hint_prompt, options={"temperature": 0.1, "num_predict": 50})
        tool_hint_response = tool_hint_response_obj['response'].strip()
    except requests.exceptions.ConnectionError:
        yield "Oops! üò¨ I'm having a little trouble connecting to my brain (Ollama server). Please make sure Ollama is running in your terminal!"
        return
    except Exception as e:
        print(f"ERROR: Ollama tool hint generation failed: {e}")
        tool_hint_response = ""

    suggested_tool = "GENERAL"
    if tool_hint_response.startswith("TOOL_HINT:"):
        suggested_tool = tool_hint_response.replace("TOOL_HINT:", "").strip().upper()

    print(f"DEBUG: Suggested Tool: {suggested_tool}")

    combined_context = ""

    if "only not completed" in query_lower or "just show pending" in query_lower or ("pending" in query_lower and "tasks" in query_lower):
        suggested_tool = "TASKS_PENDING"
    elif "only completed" in query_lower or ("completed" in query_lower and "tasks" in query_lower):
        suggested_tool = "TASKS_COMPLETED"
    elif "all tasks" in query_lower or ("tasks" in query_lower and "pending" not in query_lower and "completed" not in query_lower):
        suggested_tool = "TASKS_ALL"
    
    if ("code" in query_lower or "program" in query_lower or "script" in query_lower) and \
       ("input" in query_lower or "hardcode" in query_lower or "modify" in query_lower or "change" in query_lower or "different version" in query_lower or "write" in query_lower or "create" in query_lower):
        suggested_tool = "CODE_MODIFICATION"


    if suggested_tool.startswith("TASKS"):
        tasks = get_tasks(user_id) # Pass user_id, no is_guest
        pending_tasks = [task for task in tasks if not task.get('completed', False)]
        completed_tasks = [task for task in tasks if task.get('completed', False)]
        response_parts = []

        if suggested_tool == "TASKS_PENDING":
            if pending_tasks:
                response_parts.append("Here are your **pending tasks**, ready to be crushed! üí™\n")
                for task in pending_tasks:
                    response_parts.append(f"- {task['task']} (Due: {task['due_date']})\n")
            else:
                response_parts.append("Great news! üéâ You have **no pending tasks**! You're on top of things! ‚ú®")
        elif suggested_tool == "TASKS_COMPLETED":
            if completed_tasks:
                response_parts.append("Fantastic job! üéâ Here are your **completed tasks**:\n")
                for task in completed_tasks:
                    response_parts.append(f"- {task['task']} (Due: {task['due_date']})\n")
            else:
                response_parts.append("You haven't marked any tasks as completed yet. Time to get started! üéØ")
        elif suggested_tool == "TASKS_ALL":
            if tasks:
                response_parts.append("Here's a look at **all your tasks**, both pending and completed! üìù\n")
                for task in tasks:
                    status = "Completed! üéâ" if task.get('completed', False) else "Pending..."
                    response_parts.append(f"- {task['task']} (Due: {task['due_date']}) - {status}\n")
            else:
                response_parts.append("You currently have no tasks added. Let's set some goals! üéØ")

        yield "".join(response_parts)
        return
    elif suggested_tool == "SYLLABUS":
        subjects = get_all_subjects(user_id) # Pass user_id, no is_guest
        subject_list_for_response = "\n".join([f"- {s['name']}: {', '.join(s['topics'])}" for s in subjects])
        if subject_list_for_response:
            yield f"Here's your academic roadmap and subjects! Let's conquer these together! üöÄ\n{subject_list_for_response}"
        else:
            yield "It looks like your academic roadmap is empty for now. Time to add some exciting subjects! üìö"
        return
    elif suggested_tool == "WEB_SEARCH":
        web_result = search_resources(query)
        if "No information found on the web." not in web_result and \
           "Error fetching information from the web" not in web_result and web_result:
            combined_context += f"Web Search Information: {web_result}\n\n"
        else:
            yield "I searched the web but couldn't find specific information for that query. Would you like to try asking something else? ü§î"
            return
    elif suggested_tool == "RAG":
        rag_context = get_relevant_context(query)
        if rag_context and rag_context != "No relevant context found in the syllabus or knowledge base.":
            combined_context += f"Knowledge Base Information: {rag_context}\n\n"
        else:
            web_result = search_resources(query)
            if "No information found on the web." not in web_result and \
               "Error fetching information from the web" not in web_result and web_result:
                combined_context += f"Web Search Information: {web_result}\n\n"
            else:
                yield "I looked into my knowledge base and also searched the web, but couldn't find a direct answer for that. Can you tell me more about what you're looking for? üßê"
                return
    # Direct pass-through for CODE_MODIFICATION to LLM
    elif suggested_tool == "CODE_MODIFICATION":
        print("DEBUG: Directing CODE_MODIFICATION query to LLM with full context.")
        # No specific tool action here, just let the LLM handle it with its knowledge and context
        # The prompt itself will guide it to provide code and explanation

    # --- Generate Final Response (streaming) if not handled by a specific tool ---
    if combined_context.strip():
        full_prompt += f"\n--- Additional Context ---\n{combined_context.strip()}\n"
    else:
        full_prompt += "\n--- No specific external context found for this query. Relying on general knowledge and conversation history.---\n"

    # Append the user query to the prompt, with a simple EduMate prefix
    full_prompt += f"\nUser: {query}\nEduMate:"

    try:
        for chunk in ollama.generate(model=OLLAMA_MODEL, prompt=full_prompt, options={"temperature": 0.8, "num_predict": 2500}, stream=True):
            yield chunk['response']
    except requests.exceptions.ConnectionError:
        print("ERROR: Ollama server not running. Please ensure Ollama is running.")
        yield "Oops! üò¨ I'm having a little trouble connecting to my brain (Ollama server). Please make sure Ollama is running."
    except Exception as e:
        print(f"ERROR: Ollama response generation failed: {e}")
        yield "Oh dear! üòî An error occurred while trying to generate a response. Please try again! I'm here to support you. ‚ú®"
